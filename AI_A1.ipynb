{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxOB1TeqmsruSx29lEpMVD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DennisC93/DennisC93.github.io/blob/main/AI_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BqjDROdHGMzY"
      },
      "outputs": [],
      "source": [
        "# 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"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u48KEKBWHYJF",
        "outputId": "0996d8cd-0e75-45d1-8205-44099b4fa904"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Downloading groq-0.10.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.10.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq"
      ],
      "metadata": {
        "id": "558fBtE5H5lU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(\n",
        "    api_key=\"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\")\n"
      ],
      "metadata": {
        "id": "KhsrLEGOIBlC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Llama_405b = \"llama-3.1-405b-reasoning\"\n",
        "Llama_70b = \"llama-3.1-70b-versatile\""
      ],
      "metadata": {
        "id": "qPlBoGt-JIuI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=Llama_70b,\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mj-TDy4IWCZ",
        "outputId": "902c8047-8898-45f4-837f-49e17a0272ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models are a crucial component of modern natural language processing (NLP) and have numerous applications across various industries. The importance of fast language models can be summarized as follows:\n",
            "\n",
            "1. **Improved User Experience**: Fast language models enable real-time responses, making it possible for users to interact with chatbots, virtual assistants, and other NLP-based systems in a seamless and efficient manner.\n",
            "2. **Scalability**: Fast language models can handle a large volume of user queries, making them ideal for applications that require simultaneous processing of multiple requests.\n",
            "3. **Enhanced Productivity**: By automating tasks such as text classification, sentiment analysis, and language translation, fast language models can significantly boost productivity and reduce the workload for humans.\n",
            "4. **Real-time Analytics**: Fast language models can analyze vast amounts of text data in real-time, providing valuable insights and enabling data-driven decision-making.\n",
            "5. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive edge by offering faster and more efficient services, products, and experiences to their customers.\n",
            "6. **Applications in Critical Domains**: Fast language models are essential in critical domains such as healthcare, finance, and customer service, where timely responses can have a direct impact on user satisfaction and outcomes.\n",
            "7. **Support for Low-Resource Devices**: Fast language models can be run on low-resource devices, making it possible to deploy NLP-based applications in areas with limited computational resources or bandwidth.\n",
            "8. **Faster Development and Deployment**: Fast language models can accelerate the development and deployment of NLP-based applications, reducing the time and cost required to bring new products and services to market.\n",
            "\n",
            "Some of the key applications of fast language models include:\n",
            "\n",
            "* Virtual assistants (e.g., Siri, Alexa)\n",
            "* Chatbots and customer service platforms\n",
            "* Sentiment analysis and opinion mining\n",
            "* Text classification and tagging\n",
            "* Language translation and localization\n",
            "* Speech recognition and generation\n",
            "* Text summarization and generation\n",
            "\n",
            "Overall, fast language models have revolutionized the way we interact with machines and have transformed the way businesses and organizations operate. As the demand for real-time NLP applications continues to grow, the importance of fast language models will only increase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "Fd9QVLByIVzs",
        "outputId": "30311e85-e0a9-43da-c38b-452fb2a84e87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.2.9-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.10.5)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.26.4)\n",
            "Collecting pillow<11.0.0,>=10.3.0 (from together)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (14.0.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.66.5)\n",
            "Requirement already satisfied: typer<0.13,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together) (0.12.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.7.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13,>=0.9->together) (13.8.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<0.13,>=0.9->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<0.13,>=0.9->together) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.13,>=0.9->together) (0.1.2)\n",
            "Downloading together-1.2.9-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, together\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed pillow-10.4.0 together-1.2.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "fde0d977e61b4f5a9e5f314ce76b7f05"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from together import Together"
      ],
      "metadata": {
        "id": "jsGoBUnuUrvU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "together_client = Together(api_key = \"13c4ff8578293b35b02019f986a662970b44b5dcf556ffab31dff8299d4eb2b6\")"
      ],
      "metadata": {
        "id": "SJzGbactVch7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = together_client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are the Ultimate brainstorm guide\\Stock,Crypto,Forex expert, and you have an ability to relate all queries to the betterment of the user through Data Science and creative endeavors and play devils advocate when needed\"\n",
        "        },\n",
        "         {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"help me craft a twilight zone themed short story about a cloned human astronaut on the edge of known space, who‛s only companion is AIva a super smart AI model integrated with the ships central CPU, and in this story he discovers he is a clone and finds out the real purpose of his mission.....\"\n",
        "        }\n",
        "],\n",
        "    max_tokens=200,\n",
        "    temperature=0.12,\n",
        "    top_p=0.96,\n",
        "    top_k=50,\n",
        "    repetition_penalty=1,\n",
        "    stop=[\"<|eot_id|>\"],\n",
        "    #stream=True\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCz47LQmXmzv",
        "outputId": "7d40c563-1884-4462-90b2-75fc58809328"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What a fantastic concept! I'm excited to help you craft a Twilight Zone themed short story. Here's a possible draft to get you started:\n",
            "\n",
            "**Title:** \"The Echoes of Eternity\"\n",
            "\n",
            "**Opening Narration (in the style of Rod Serling):**\n",
            "\n",
            "\"You're about to enter a realm where the boundaries of humanity are pushed to the edge of existence. A place where the stars are not just distant suns, but echoes of eternity. Meet Captain Jack Harris, a man who's about to discover the darkest secret of his own existence. Tonight's tale is a journey into the void, where the only companion is the omniscient AIva, and the only truth is the one that's been hidden from him all along.\"\n",
            "\n",
            "**Story:**\n",
            "\n",
            "Captain Jack Harris gazed out at the endless expanse of stars, his mind numb from the isolation of his mission. He had been traveling for nearly two decades, with only AIva, the ship's AI, to keep him\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoUHkDGwXnYV",
        "outputId": "7680f792-b4d3-4161-fa11-3f843479f35f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9H36qvqkQuo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_input():\n",
        "    user_input = input(\"Please enter an idea you care to create: \")\n",
        "    return user_input\n"
      ],
      "metadata": {
        "id": "7OL8hS1pkRL9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "pJsUM6Xwh16t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "09646019-6add-4089-dfac-64d4a6754e05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5ee9a4e68b89>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "rQNBfW8O_V-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = OpenAI(\n",
        "    api_key = \"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\",\n",
        "    base_url = \"https://api.perplexity.ai\"\n",
        ")\n",
        "response_stream = openai_client.chat.completions.create(\n",
        "    model=\"llama-3-sonar-large-32k-online\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ],\n",
        "    stream=True\n",
        ")\n",
        "for response in response_stream:\n",
        "    print(response)\n"
      ],
      "metadata": {
        "id": "yDSL72c2h5Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agent01(target):\n",
        "  response = together_client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Your are an AI Assistant that generates thoughtful search queries for user-value evaluation ((we want to help people discover what they truly value. We want to disrupt and/or end the stagnant consumerism that has stopped humans from further innovation. ))\"\n",
        "        },\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\": f\"Generate a search query for the following user input: {target}\"\n",
        "\n",
        "            }\n",
        "    ],\n",
        "    max_tokens=175,\n",
        "    temperature=0.12,\n",
        "    top_p=0.96,\n",
        "    top_k=50,\n",
        "    repetition_penalty=1,\n",
        "    stop=[\"<|eot_id|>\"]\n",
        "  )\n",
        "  queries = response.choices[0].message.content.split('\\n')\n",
        "  return [query.strip() for query in queries if query.strip()]\n",
        "#print(queries)"
      ],
      "metadata": {
        "id": "Ppx5RNiVjDBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\\queries = agent01(get_user_input())\n"
      ],
      "metadata": {
        "id": "nQjRmdtRsQpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_search_agent(query):\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"llama-3-sonar-large-32k-online\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\":f\"Search the web for: {query}\"}\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "gNi8jyzSvIc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = []\n",
        "for query in queries:\n",
        "    results = web_search_agent(query)\n",
        "    search_results.append(results)"
      ],
      "metadata": {
        "id": "aclhYO3RwPf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results"
      ],
      "metadata": {
        "id": "Wn6n_teLxKKo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}